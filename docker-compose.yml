version: '3'

services:

  startup:
    depends_on:
      - zookeeper
      - kafka
      - arangodb
    build: ./startup
    restart: always
    container_name: startup
    networks:
      - kafka_net
      - arango_net
      - startup_net
    ports:
      - "80"
    volumes:
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}
      # set RESETDATABASE to "yes" if you want to drop database on startup and recreate
      - RESETDATABASE=${RESETDATABASE:-no}

  # proxy routes OAuth2 requests (/auth, /code) to auth service,
  # and the rest to main http-handlers.  TODO: add load balancing with multiple handlers.
  proxy:
    depends_on:
      - auth
      - http-handler
      - well-known
    build: ./proxy
    container_name: proxy
    restart: always
    networks:
      - http_net
    ports:
        - "${BIND:-0.0.0.0}:${PORT_HTTPS:-443}:443"
        - "${BIND:-0.0.0.0}:${PORT_HTTP:-80}:80"
    volumes:
      - ./proxy/nginx.conf:/etc/nginx/nginx.conf
      - ./proxy/dev-sites-enabled/:/etc/nginx/sites-templates/
      - ./proxy/dev-certs/:/certs/
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
      # Need the letsencrypt_www_data volume so admin's certbot command can put web-accessible files there
      - letsencrypt_www_data:/var/www/letsencrypt
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}
      - DOMAIN=${DOMAIN:-localhost}
      - NODE_TLS_REJECT_UNAUTHORIZED=${NODE_TLS_REJECT_UNAUTHORIZED:-""}
    command:
      - /entrypoint.sh

  auth:
    depends_on:
      - startup
    build:
      context: ./auth
    container_name: auth
    restart: always
    networks:
      - http_net
      - arango_net
      - startup_net
    ports:
      - "80"
    volumes:
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
    environment:
      - NODE_TLS_REJECT_UNAUTHORIZED=${NODE_TLS_REJECT_UNAUTHORIZED:-""}
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}
    command:
      - /entrypoint.sh

  # http-handler is in charge of maintaining connectiongs to clients and starting
  # the first message for a request into Kafka
  http-handler:
    depends_on:
      - startup
    build:
      context: ./http-handler
    restart: always
    container_name: http-handler
    networks:
      - startup_net
      - http_net
      - kafka_net
      - arango_net
    ports:
      - "34135:80"
    volumes:
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}
      - IGNORE_SCOPE=${IGNORE_SCOPE:-""}
      - NODE_TLS_REJECT_UNAUTHORIZED=${NODE_TLS_REJECT_UNAUTHORIZED:-""}

  sync-handler:
    depends_on:
      - startup
      - proxy
    build:
      context: ./sync-handler
    restart: always
    container_name: sync-handler
    networks:
      - startup_net
      - kafka_net
      - arango_net
      - http_net
    volumes:
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}
      - NODE_TLS_REJECT_UNAUTHORIZED=${NODE_TLS_REJECT_UNAUTHORIZED:-""}
      - IGNORE_SCOPE=${IGNORE_SCOPE:-""}

  write-handler:
    depends_on:
      - startup
    build:
      context: ./write-handler
    restart: always
    container_name: write-handler
    networks:
      - startup_net
      - kafka_net
      - arango_net
    volumes:
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}

  users:
    depends_on:
      - startup
    build:
      context: ./users
    restart: always
    container_name: users
    networks:
      - startup_net
      - kafka_net
      - arango_net
    volumes:
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}

  token-lookup:
    depends_on:
      - startup
    build:
      context: ./token-lookup
    restart: always
    container_name: token-lookup
    networks:
      - startup_net
      - kafka_net
      - arango_net
    volumes:
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}

  rev-graph-update:
    depends_on:
      - startup
    build:
      context: ./rev-graph-update
    restart: always
    container_name: rev-graph-update
    networks:
      - startup_net
      - kafka_net
      - arango_net
    volumes:
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}

  hyperledger-fabric:
    depends_on:
      - startup
    build:
      context: ./hyperledger-fabric
    restart: always
    container_name: hyperledger-fabric
    networks:
      - startup_net
      - kafka_net
      - arango_net
    volumes:
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}

  graph-lookup:
    depends_on:
      - startup
    build:
      context: ./graph-lookup
    restart: always
    container_name: graph-lookup
    networks:
      - startup_net
      - kafka_net
      - arango_net
    volumes:
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}

  well-known:
    depends_on:
      - startup
    build:
      context: ./well-known
    restart: always
    container_name: well-known
    networks:
      - startup_net
      - http_net
    volumes:
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
    ports:
      - "80"
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}

#  tests:
#    # depends_on:
#    #   - startup
#    build:
#      context: ./tests
#    container_name: tests
#    networks:
#      - startup_net
#      - kafka_net
#      - arango_net
#      - http_net
#    volumes:
#      - .:/code
#      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
#    environment:
#      - NODE_ENV=${NODE_ENV:-development}
#      - DEBUG=${DEBUG:-""}

  # admin container has all the service names and volumes mapped, so you
  # can interact with them easily from this service.
  admin:
    build: ./admin
    volumes:
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
      - arangodb_data:/volumes/arangodb
      - arangodb_apps_data:/volumes/arangodb_apps
      - zookeeper_data:/volumes/zookeeper
      - kafka_data:/volumes/kafka
      - .:/code
      - /var/run/docker.sock:/var/run/docker.sock
      - letsencrypt_www_data:/var/www/letsencrypt
      # Need to map proxy's dev-certs for letsencrypt to save all its stuff where proxy can get it
      - ./proxy/dev-certs:/etc/letsencrypt
    command: bash
    networks:
      - startup_net
      - kafka_net
      - arango_net
      - http_net
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}

  kafka:
    image: wurstmeister/kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    restart: always
    hostname: kafka
    networks:
      - kafka_net
    environment:
      KAFKA_ADVERTISED_HOST_NAME: "kafka"  # NOTE: this only allows services inside this docker network
      KAFKA_ADVERTISED_PORT: "9092"        # to connect to kafka.  Set to machine's IP if you want external.
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_HEAP_OPTS: "-Xmx1g -Xms512M"
      KAFKA_BROKER_ID: 1
      JMX_PORT: 9999
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - kafka_data:/var/lib/kafka

#  exporter:
#    image: prom/node-exporter:latest
#    ports:
#      - "9100:9100"
#    networks:
#      - prometheus

#  grafana:
#    image: grafana/grafana
#    ports:
#      - "3000:3000"
#    depends_on:
#      - prometheus

#  cadvisor:
#    image: google/cadvisor
#    volumes:
#      - /:/rootfs:ro
#      - /var/run:/var/run:rw
#      - /sys:/sys:ro
#      - /var/lib/docker/:/var/lib/docker:ro
#    ports:
#      - "8090:8080"
#    networks:
#      - arango_net
#      - kafka_net
#      - http_net
#    restart: always

#  jmx-exporter:
#    build: ./jmx-exporter
#    ports:
#      - "8080:8080"
#    networks:
#      - prometheus
#      - kafka_net
#    links:
#      - kafka
#    environment:
#      - JMX_PORT=9999
#      - JMX_HOST=kafka
#      - HTTP_PORT=8080
#      - JMX_EXPORTER_CONFIG_FILE=kafka.yml

#  prometheus:
#    image: prom/prometheus
#    container_name: prometheus
#    restart: always
#    volumes:
#      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
#      - kafka_data:/var/lib/kafka
#      - arangodb_data:/var/lib/arangodb3
#      - arangodb_data:/var/lib/arangodb3-apps
#    command: "--config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/prometheus"
#    networks:
#      - kafka_net
#      - prometheus
#    ports:
#      - "9090:9090"
#    depends_on:
#      - exporter
#    links:
#      - jmx-exporter

  # Needed for installing native Node dependencies
  yarn:
    build:
      context: ./yarn
    volumes:
      - .:/code

  # letsencrypt will go get HTTPS certificates for you if DOMAIN is not localhost
  # NOTE: letsencrypt has a limit of 5 certificates per top domain per week,
  # so you don't want this thing running often.  Once it runs, SAVE THE CERTIFICATES
  # TO A SAFE PLACE.  Otherwise if you go over the request limit and lost the private
  # key, you're just out of luck for 7 days.
  letsencrypt:
    build: ./letsencrypt
    container_name: letsencrypt
    restart: "no"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - letsencrypt_www_data:/var/www/letsencrypt
      - ./proxy/dev-certs:/certs
    networks:
      - http_net
    environment:
      - SERVER_CONTAINER=proxy
      - DOMAINS=${DOMAIN:-localhost}
      - EMAIL=${LETSENCRYPTEMAIL:-info@openag.io}
      - WEBROOT_PATH=/var/www/letsencrypt
      - CERTS_PATH=/certs/${DOMAIN:-nodomain}
      - CHECK_FREQ=7

  # Arango is the main backend where core data and graph is stored
  arangodb:
    image: arangodb
    container_name: arangodb
    restart: always
    networks:
      - arango_net
    volumes:
      - arangodb_data:/var/lib/arangodb3
      - arangodb_data:/var/lib/arangodb3-apps
    ports:
      - "8529:8529"
    environment:
      # - ARANGO_RANDOM_ROOT_PASSWORD=1
      - ARANGO_NO_AUTH=1
      - ARANGO_STORAGE_ENGINE=rocksdb
      - ARANGO_STATISTICS=0
    command: ["arangod", "--server.statistics", "true"]


  # zookeeper and kafka entries are based on:
  # from https://github.com/wurstmeister/kafka-docker/blob/master/docker-compose.yml
  zookeeper:
    image: wurstmeister/zookeeper
    restart: always
    networks:
      - kafka_net
    ports:
      - "2181"
    volumes:
      - zookeeper_data:/var/lib/zookeeper

    # hitman container will kill other containers using Pumba for resiliency test.
  #  hitman:
  #    image: gaiaadm/pumba:master
  #    container_name: hitman
  #    restart: always
  #   volumes:
  #      - /var/run/docker.sock:/var/run/docker.sock
  #    command: pumba --random --interval 1h kill --signal SIGKILL

  indexer:
    depends_on:
      - startup
    build:
      context: ./indexer
    restart: always
    container_name: indexer
    networks:
      - startup_net
      - kafka_net
      - arango_net
    volumes:
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}

  webhooks:
    depends_on:
      - startup
      - proxy
    build:
      context: ./webhooks
    restart: always
    container_name: webhooks
    networks:
      - startup_net
      - kafka_net
      - arango_net
      - http_net
    volumes:
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}
      - SSL_ALLOW_SELF_SIGNED=1

  permissions-handler:
    depends_on:
      - startup
    build:
      context: ./permissions-handler
    restart: always
    container_name: permissions-handler
    networks:
      - startup_net
      - kafka_net
      - arango_net
    volumes:
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}

  shares:
    depends_on:
      - startup
    build:
      context: ./shares
    restart: always
    container_name: shares
    networks:
      - startup_net
      - kafka_net
      - arango_net
    volumes:
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - DEBUG=${DEBUG:-""}

  yield-tiler:
    depends_on:
      - startup
    build:
      context: ./yield-tiler
    restart: always
    container_name: yield-tiler
    networks:
      - startup_net
      - kafka_net
      - arango_net
    volumes:
      - .:/code
      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - NODE_TLS_REJECT_UNAUTHORIZED=${NODE_TLS_REJECT_UNAUTHORIZED:-""}
      - DEBUG=${DEBUG:-""}

#  winfield-fields-sync:
#    depends_on:
#      - startup
#    build:
#      context: ./winfield-fields-sync
#    restart: always
#    container_name: winfield-fields-sync
#    networks:
#      - startup_net
#      - kafka_net
#      - arango_net
#    volumes:
#      - .:/code
#      - ./oada-srvc-docker-config.js:/oada-srvc-docker-config.js
#    environment:
#      - NODE_ENV=${NODE_ENV:-development}
#      - DEBUG=${DEBUG:-""}



volumes:
  arangodb_data:
  arangodb_apps_data:
  kafka_data:
  zookeeper_data:
  letsencrypt_www_data:

networks:
  arango_net:
  kafka_net:
  http_net:
  startup_net:
  #prometheus:
